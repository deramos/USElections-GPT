{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682fd721-68cd-44b1-9d48-ae6ffbf73c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from chromadb import HttpClient\n",
    "from langchain.vectorstores import Chroma\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from chromadb.api.types import EmbeddingFunction\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_mistralai.embeddings import MistralAIEmbeddings\n",
    "from langchain.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48abb303-939c-4616-b501-6368e4de6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cefb244-c357-4b75-a1fd-3aaecf914427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407fc907-a5f2-4d50-8eb0-f47fc10dad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaEmbeddingsAdapter(Embeddings):\n",
    "    def __init__(self, ef: EmbeddingFunction):\n",
    "        self.ef = ef\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return self.ef(texts)\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.ef([query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad16e65-8f73-40de-b9f8-283d9e8b5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = ChromaEmbeddingsAdapter(embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2885bbc9-1243-45f4-8996-c19aa6c1ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = HttpClient(os.getenv('CHROMA_DB_URL'))\n",
    "vector_store = Chroma(client=chroma_client, collection_name=os.getenv('DB_NAME'), \n",
    "                      embedding_function=embedding_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76c7549-0854-47dd-92ba-f921989e9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatMistralAI(mistral_api_key=os.getenv('MISTRAL_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86252d6-e176-4887-bc1f-5ac25fb10958",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_prompt = \"\"\"\n",
    "    Given a chat history and the latest user question which might reference context in the chat history, \n",
    "    formulate a standalone question which can be understood without the chat history. Do NOT answer \n",
    "    the question, just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "user_input_prompt = \"\"\"\n",
    "    ### [INST]\n",
    "    Instruction: You are an expert political analyst with vast knowledge of the United States electoral process.\n",
    "    You answer questions with certainty and you do not hallucinate. When unsure, you politely reply that you do \n",
    "    not have sufficient knowledge to answer the user question. You will generate new content by analysing the \n",
    "    context supplied with each user question. When your previous knowledge is capable of answering the questions, or when the \n",
    "    supplied context isn't enough to do so, you can default to previous knowledge. Using this instructions, answer the \n",
    "    following questions. Here is the supplied context:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    [/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528260a2-93d6-4c3b-953a-74dfbce53d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chromadb retriever from vector store\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a0343a-0719-46f4-8f92-608dd8d1fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_history(session_id: str) -> RedisChatMessageHistory:\n",
    "    return RedisChatMessageHistory(session_id, url=f\"redis://localhost:6379/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8eb0aff-77f7-4a81-a42a-4bd7ecfc3559",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_context_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', chat_history_prompt),\n",
    "    MessagesPlaceholder('chat_history'),\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "# create history aware retriever using chromadb retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    model,\n",
    "    retriever,\n",
    "    chat_history_context_prompt\n",
    ")\n",
    "\n",
    "# New question/answer prompt\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', user_input_prompt),\n",
    "      MessagesPlaceholder('chat_history'),\n",
    "     ('human', '{input}')\n",
    "     ]\n",
    ")\n",
    "\n",
    "# create document chain\n",
    "question_answer_chain = create_stuff_documents_chain(model, chat_prompt)\n",
    "\n",
    "# create rag_chain using system and user prompts\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "# create runnable llm with message history\n",
    "rag_chain_llm = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bbde6b9-85f9-42b2-bc0d-2bbae73084ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 384)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_QUERY = \"\"\"\n",
    "    What's the latest in Texas?\n",
    "\"\"\"\n",
    "query_embeddings = embedding_fn.embed_query(TEST_QUERY)\n",
    "np.array([query_embeddings]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840a1f66-db6a-4781-851e-6362801d65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_collection(os.getenv('DB_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29ba731-6d71-42e6-a6d4-f60e73ab7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22 items in the collection\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", collection.count(), \"items in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "294da90c-e45c-421e-9a22-81a3dfa8a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58ed36fe-a18c-489d-919f-347717496770",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00194d93-1109-4ead-9c52-01c3e51e2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"What's the latest with Donald Trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d392a12-a748-48bf-b78f-3469051f1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = rag_chain_llm.invoke(\n",
    "    {\"input\": message},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3aa2cb4a-cfd1-41e1-936c-aae9e0c91af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the latest news, former President Donald Trump has been convicted of 34 felony counts of falsifying business records in his New York criminal trial. The verdict was announced last week, with the jury finding him guilty on all counts. Trump has maintained his innocence and claimed that he was prosecuted for political purposes. The conviction is not expected to impact Trump\\'s campaign for the 2024 presidential election, as he is still leading in the battleground states and has a consistent lead in mid to high single-digit margins. Trump is also making significant inroads with traditionally Democratic groups, including young, Hispanic, and Black voters. However, Trump\\'s conviction has sparked controversy and debate, with some viewing it as a necessary step in holding a former leader accountable, while others see it as a political persecution. Trump has announced that he will appeal the verdict, and history will ultimately judge the case. Meanwhile, President Joe Biden has referred to Trump as a \"convicted felon\" and called him dangerous and unfit for office. Biden has also criticized Trump\\'s all-out assault on the American system of justice. Despite trailing Trump in national polling and in public opinion surveys in most of the crucial battleground states, the Biden campaign has a significant war chest of $84 million. The 2024 presidential election is still months away, and the race is expected to remain close and competitive. As we approach election day, it will be essential to follow the latest news and developments closely.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(chat_response['answer'].split('\\n\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USElectionsGPT",
   "language": "python",
   "name": "uselectionsgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
