{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814d98b1-5f48-44a5-a4b4-83aa5ca8be9c",
   "metadata": {},
   "source": [
    "# News Article Summarization. \n",
    "This notebook prepares news articles to be inserted into the ChromaDB vector database. First, it creates a summary of the news article, then it identifies important Named Entities such as the names of politicians, locations, and relevant dates. Having a news summary allows us to quickly perform small-to-big retrieval; finding the full article from it's brief overview. This method helps us evaluate the Language Learning Model (LLM) more effectively. Additionally, the identified entities will be used as metadata and embedded with the news articles, aiding in fine-tuning and evaluating the LLM.\n",
    "\n",
    "For more insight into this approach, check out this YouTube video by Jerry Liu, Founder of LlmamaIndex: https://youtu.be/TRjq7t2Ms5I."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0161c5e3-0925-4bac-b2f7-f71936c03665",
   "metadata": {},
   "source": [
    "## Config & Install Libraries\n",
    "Check if Huggingface transformers and required libraries are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50daf810-a778-4ac6-b36e-04f51dfd9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers sentencepiece sentence-transformers datasets spacy chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb674b7-f4c8-4a30-95d3-2545b512235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa7f79-1f93-4386-96b9-1fd0aa78fbbe",
   "metadata": {},
   "source": [
    "## News Summary Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d6caa0e-2aea-44e9-9379-5cc09090d583",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from util import utils\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba077d4f-7a01-433c-8251-ad0adab8b0e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a75d2-a614-4366-afaa-0d60ee7ea43f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97dd4511-4006-4dc6-a458-c3060c9ea212",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "collection_name = 'raw-news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19e76648-2780-403b-87c1-b3c67ae09db1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "batch_date = {'$gte': '2024-04-12', '$lte': '2024-04-13'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85a090e1-9b4f-4787-a03b-d78fe0754547",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MONGO_CONN_STRING = 'mongodb://admin:7QdQ3v0M50<>@192.168.8.166:27017/'  # os.getenv(\"MONGO_CONNECTION_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf02214-764f-404a-9401-44a273c876c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(MONGO_CONN_STRING)\n",
    "db = mongo_client.get_database(os.getenv(\"MONGO_DB_NAME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a3dda-cc27-4648-be12-f799485a38dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8651a5f5-0a69-41d3-bb6e-fe5a4c9017e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "news_articles = json.loads(json.dumps(list(db.get_collection(collection_name).find({'created_at': batch_date})), cls=utils.CustomMongoDecoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "123e5e2e-1e8d-45a9-aa4c-5b350d3a3ccc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for article in news_articles:\n",
    "    article['processed_content'] = ''.join(art.strip() for art in article['raw_content'])\n",
    "    article['processed_content'] = article['processed_content'].replace('\\xa0', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f1a7318-5d23-46a2-8f0f-09e018f26e7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sen. Joe Manchin, a critical swing vote in the closely divided Senate, said Wednesday that from now on, he will only vote to confirm nominees who have the support of at least one Republican senator.“I’m going to be very honest with everybody, if my Democratic colleagues and friends can’t get one Republican vote, don’t count on me. You can’t make it bipartisan, don’t count on me,” said the West Virginia Democrat who haswill begin in January 2025.“I’m not leaving this place unless I can practice what I preach and I’m preaching, basically bipartisanship,” he said. “This is my little way of doing it.”Manchin’s comments came in response to questions from CNN about President Joe Biden’s nominee for the Third Circuit Court of Appeals, Adeel Mangi, who would be the first Muslin-American on a federal appeals court. Many Republicans are vehemently opposed to him and accuse him having extreme views and part of a group they call antisemitic. Top Democrats strongly defend him and are pressing for a floor vote, after he was narrowly approved in the Senate Judiciary Committee in January, although they acknowledge not knowing if they have the votes to confirm him.On Thursday, Manchin confirmed he would vote against Mangi.One Democrat, Sen. Catherine Cortez Masto of Nevada, announced her opposition to Mangi on Tuesday.Sen Lisa Murkowski, a centrist Republican from Alaska who often votes across the aisle, told CNN Wednesday she needs to examine Mangi’s record before deciding how she will vote.For Manchin, he said Wednesday there is one exception to his newly announced requirement of bipartisanship: “That’s my requirement unless they’re bats*** crazy. If they’re bats*** crazy left, I’m gonna vote against them anyway. If they’re halfway decent, they’ll get at least one Republican to vote for them.”Asked if he still sees a viable path for Mangi to be confirmed, Judiciary Committee Chairman Dick Durbin said, “it certainly is going to be a challenge with the many things people are saying,” referring to vocal opposition to Mangi.© 2024 Cable News Network. A Warner Bros. Discovery Company. All Rights Reserved.CNN Sans ™ & © 2016 Cable News Network.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article['processed_content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90714437-0414-4872-bf02-8203d7fcd556",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Load Summarization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b60181e-0b78-42ab-8e56-7625cf061544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'google/bigbird-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e956a8a-041a-40db-ab2b-d58540010d2d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load fine-tuned BART model for summarization\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def summarize_article(text: str):\n",
    "    # Tokenize and encode the text\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs.input_ids, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "    \n",
    "    # Decode and print the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # return summary\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05a060-9c35-4b9b-880c-80a1d191294f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b10d8c-9895-47e5-9a3b-c183ca031c74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REQUIRED_FIELDS = ['PERSON', 'GPE', 'NORP', 'EVENT', 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcddf58-cf04-4582-8237-bbb6f65aa923",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "def perform_ner(text: str):\n",
    "    \n",
    "    # Load the English language model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract named entities\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c52348-6302-446c-a5a2-914a30f3414d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# postprocess the named entities to select the required entity tags\n",
    "def postprocess_entities(entities):\n",
    "    processed_entities = defaultdict(set)\n",
    "    \n",
    "    for entity, label in entities:\n",
    "        if label in REQUIRED_FIELDS:\n",
    "            processed_entities[label].add(entity)\n",
    "    processed_entities = {key: list(value) for key, value in processed_entities.items()}\n",
    "    return processed_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07deb794-1e36-4fc8-8c2e-641fdb4ad483",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Perform Summarization and NER on News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c751ab-d550-43e7-a548-59623d86592f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392d771-4c99-46e7-9933-db080ddbd54e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for news in news_articles:\n",
    "#     summary = summarize_article(news['processed_content'])\n",
    "#     entities = postprocess_entities(perform_ner(news['processed_content']))\n",
    "\n",
    "#     news['news_summary'] = summary\n",
    "#     news['entities'] = entities\n",
    "\n",
    "#     # filter criteria\n",
    "#     filter_criteria = {'_id': ObjectId(news['_id'])}\n",
    "    \n",
    "#     # Define the update operation\n",
    "#     update_data = {\n",
    "#         '$set': {\n",
    "#             'processed_news_content': news['processed_content'],\n",
    "#             'news_summary': summary,\n",
    "#             'entities': entities\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "#     # Update the Mongo document\n",
    "#     result = db.get_collection('raw-news').update_one(filter_criteria, update_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c5002-a6df-4a6c-9408-27040d836c51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Save content and metadata on Chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d012113-59fb-47d7-b54b-1ba7dd312bf3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee664f67-c44f-4847-9993-87cb85050d4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48516153-a652-48d4-9e95-2a74c3c9376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection('us-election-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f83732e-2f26-44da-abbb-2933deb43685",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_collection(name='us-election-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d511bfb-ec0a-4271-997d-8156942683ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-04-15 15:40:05.974135 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running CoreML_6637485038947908539_1 node. Name:'CoreMLExecutionProvider_CoreML_6637485038947908539_1_1' Status Message: Error executing model: Unable to compute the prediction using a neural network model. It can be an invalid input data or broken/unsupported model (error code: -1).\u001b[m\n"
     ]
    },
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running CoreML_6637485038947908539_1 node. Name:'CoreMLExecutionProvider_CoreML_6637485038947908539_1_1' Status Message: Error executing model: Unable to compute the prediction using a neural network model. It can be an invalid input data or broken/unsupported model (error code: -1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add news processed content and metadata to chromadb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews_articles\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnews_summary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews_articles\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnews_articles\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/chromadb/api/models/Collection.py:154\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# At this point, we know that one of documents or images are provided from the validation above\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/chromadb/api/models/Collection.py:633\u001b[0m, in \u001b[0;36mCollection._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.trychroma.com/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/chromadb/api/types.py:193\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[0;32m--> 193\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(maybe_cast_one_to_many_embedding(result))\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/chromadb/utils/embedding_functions.py:525\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Documents) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# Only download the model when it is actually used\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_model_if_not_exists()\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Embeddings, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/chromadb/utils/embedding_functions.py:468\u001b[0m, in \u001b[0;36mONNXMiniLM_L6_V2._forward\u001b[0;34m(self, documents, batch_size)\u001b[0m\n\u001b[1;32m    459\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e\u001b[38;5;241m.\u001b[39mattention_mask \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m encoded])\n\u001b[1;32m    460\u001b[0m onnx_input \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(input_ids, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray(attention_mask, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     ),\n\u001b[1;32m    467\u001b[0m }\n\u001b[0;32m--> 468\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m model_output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Perform mean pooling with attention weighting\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/USElections-GPT/venv/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running CoreML_6637485038947908539_1 node. Name:'CoreMLExecutionProvider_CoreML_6637485038947908539_1_1' Status Message: Error executing model: Unable to compute the prediction using a neural network model. It can be an invalid input data or broken/unsupported model (error code: -1)."
     ]
    }
   ],
   "source": [
    "# Add news processed content and metadata to chromadb\n",
    "collection.add(\n",
    "    documents=[news['processed_content'] for news in news_articles],\n",
    "    metadatas=[{'entities': json.dumps(news['entities']), 'summary': news['news_summary'], 'source': news['source']}\n",
    "               for news in news_articles],\n",
    "    ids=[str(news['_id']) for news in news_articles]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29c653-93de-4113-b5c3-fb578b0c80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'publication_date': news['publication_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb61a31-0fa4-44e9-865f-a6ae6e9ad34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "USElectionsGPT",
   "language": "python",
   "name": "uselectionsgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
